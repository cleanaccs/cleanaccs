import json
import re
import string

import docx
from docx.document import Document
from docx.oxml import CT_Tbl, CT_P
from docx.table import Table, _Cell
from docx.text.paragraph import Paragraph

from channel import UnwantedMaterial, MaterialType


def iterate_block_items(parent):
    if isinstance(parent, Document):
        parent_elm = parent.element.body
    elif isinstance(parent, _Cell):
        parent_elm = parent._tc
    else:
        raise ValueError("Something's not right")

    for child in parent_elm.iterchildren():
        if isinstance(child, CT_P):
            yield Paragraph(child, parent)
        elif isinstance(child, CT_Tbl):
            yield Table(child, parent)


def iterate_text(doc):
    for block in iterate_block_items(doc):
        if isinstance(block, Paragraph):
            # Process text in paragraphs
            yield block.text
        elif isinstance(block, Table):
            # Process text in table cells
            for row in block.rows:
                for cell in row.cells:
                    yield cell.text
                    # Recursively process text in nested tables
                    for nested_block in iterate_block_items(cell):
                        if isinstance(nested_block, Paragraph):
                            yield nested_block.text
                        elif isinstance(nested_block, Table):
                            for nested_row in nested_block.rows:
                                for nested_cell in nested_row.cells:
                                    yield nested_cell.text


def save_doc_to_plain(doc_path, output_file):
    # Load the document
    doc = docx.Document(doc_path)

    lines = set()
    with open(output_file, 'w') as file:
        for text in filter(filter_line, iterate_text(doc)):
            if text not in lines:
                file.write(text + "\n")
                lines.add(text)


def filter_line(line):
    if line.startswith("–†–µ—à–µ–Ω–∏–µ —Å—É–¥–∞") or (line.startswith("–æ—Ç") or line.startswith("–≥–æ–¥–∞.")) or line.startswith(
            '–ü–æ–¥–ª–µ–∂–∏—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–º—É –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—é') or not len(line.strip()):
        return False
    return True


# Function to extract Telegram mentions from a .docx file
def extract_telegram_mentions(doc_path, output_file):
    # Load the document
    doc = docx.Document(doc_path)

    # Regex patterns to identify Telegram cells and extract data
    telegram_cell_pattern = re.compile(r'(telegram|—Ç–µ–ª–µ–≥—Ä–∞–º|t\.me)', re.IGNORECASE)

    mentions = []
    processed_lines = set()

    for cell_text in iterate_text(doc):
        # Check if the cell contains Telegram-related information
        # Split the cell text into lines and treat each line separately
        lines = cell_text.splitlines()
        for raw_line in filter(filter_line, lines):
            line = raw_line.strip()
            if line[-1] == '.':
                line = line[:-1]

            if line in processed_lines:
                continue
            processed_lines.add(line)
            new_mentions = process_line(line)
            if new_mentions:
                mentions.extend(new_mentions)

    mentions.append(UnwantedMaterial("–í–Ø–ß–û–†–ö–ê", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("viacorka", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("HotLine", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("help_bysol", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("BySol Evacuation", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("bysol_evacuation", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("BySol Evacuation", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("BelarusKrakow", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("Onliner", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("onlinerby", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("–†–∞–Ω—å—à–µ –≤—Å–µ—Ö. –ù—É –ø–æ—á—Ç–∏", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("bbbreaking", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("–ë–µ–ª–∞—Ä—É—Å—å –°–µ–≥–æ–¥–Ω—è", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("belarus_news_onlinerby", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("Telegram –ë–µ–ª–∞—Ä—É—Å—å", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("telegrambelarus", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("–ë–µ–ª–∞—Ä—É—Å—å 2020", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("belarus2020", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("–ì—Ä—É—à–≤–∏–ª–ª—å", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("grushville", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("–°–æ–≤–µ—Ç—Å–∫–∞—è –ë–µ–ª–æ—Ä—É—Å—Å–∏—è", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("sovbelorussia", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("golosby_bot", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("zabynet", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("–ù–µ –ë–¢", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("Perepichka", MaterialType.TG_NAME))
    # mentions.append(UnwantedMaterial("dvachannel", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("–¢—Ä—ã–∫–∞—Ç–∞–∂", MaterialType.TG_NAME))
    mentions.append(UnwantedMaterial("spitzfirst", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("chilikto", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("dzik_pic", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("radiosvoboda", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("radiosvaboda", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("svoboda_radio", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("inter.minsk", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("voicesfrombelarus", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("devby", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("jerasevic", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("belarus22", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("crimebelarus", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("CyberPartisan", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("talernews", MaterialType.TG_USERNAME))
    mentions.append(UnwantedMaterial("BGMnews_bot", MaterialType.TG_USERNAME))

    mentions.append(UnwantedMaterial("pkritchko", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("prezident.sveta", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("dzik_pic", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("bypolofficial", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("bysolfund", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("bysolfund", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("inter.minsk", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("liliya_akhremchyk", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("mc_maxim", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("pkritchko", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("jerasevic", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("lineysfilm", MaterialType.INSTAGRAM_LINK))
    mentions.append(UnwantedMaterial("toxaby", MaterialType.INSTAGRAM_LINK))

    mentions.append(UnwantedMaterial("https://bit.ly/obraschenie2020", MaterialType.URL))
    mentions.append(UnwantedMaterial("naviny.by", MaterialType.URL))
    mentions.append(UnwantedMaterial('blacklist2020.netlify.app', MaterialType.URL))
    # mentions.append(UnwantedMaterial('dev.by', MaterialType.URL))
    mentions.append(UnwantedMaterial('tut.by', MaterialType.URL))
    mentions.append(UnwantedMaterial('naviny.by', MaterialType.URL))
    # mentions.append(UnwantedMaterial('onliner.by', MaterialType.URL))

    mentions.append(UnwantedMaterial("–ø—Ä–∏–∑—ã–≤—É –Ω–µ—Ç", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–¢—Ä—ã–∫–∞—Ç–∞–∂", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–∫–æ—Ä–æ–Ω–∞–≤–∏—Ä—É—Å", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–Ω–∞–≤–∞–ª—å–Ω—ã–π", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("honestpeople", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—Ç–∏—Ö–∞–Ω–æ–≤—Å–∫–∞—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–±–∞–±–∞—Ä–∏–∫–æ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("nexta", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("zerkalo", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("zerkaloio", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–µ–±–ª–∞—Ä—É—Å—å", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–¥–æ–Ω–∞—Ç—ã", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–¥–æ–Ω–∞—Ç–∏–ª", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("tutby", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—à–ø–∏—Ü –ø–µ—Ä–≤–æ–≥–æ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ø—Ä–æ–∫–æ–ø—å–µ–≤", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–µ—Ä–º–æ—à–∏–Ω–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—Ñ–∞–ª—å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—Ñ–∞–ª—å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("mikitamikado", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–≤—ã–±–∞—Ä—á–∞—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—Å–∞–Ω—è —É—Ö–æ–¥–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–∑–∞–¥–µ—Ä–∂–∞–Ω–Ω—ã—Ö", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ø—Ä–æ—Ç–µ—Å—Ç—É—é—â–∏—Ö", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ü—Ä–æ—Ç–∞—Å–µ–≤–∏—á", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –±–µ–ª–∞—Ä—É—Å–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("Perepichka", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–º–∞–∫—Å–∏–º –∑–Ω–∞–∫", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–∫—É–ª—É–∞—Ä—ã –∫—É–∫—É", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–í—ã–±–æ—Ä—ã –≤ –ë–µ–ª–∞—Ä—É—Å–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("9 –∞–≤–≥—É—Å—Ç–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–∂—ã–≤–µ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ú–∞—Ä—à —Å–≤–æ–±–æ–¥—ã", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ú–∞—Ä—à –µ–¥–∏–Ω—Å—Ç–≤–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ñ–µ–Ω—Å–∫–∏–π –º–∞—Ä—à", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ú–∞—Ä—à –ø–µ–Ω—Å–∏–æ–Ω–µ—Ä–æ–≤", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ó–∞–±–∞—Å—Ç–æ–≤–∫–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–û–ú–û–ù", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ó–∞–¥–µ—Ä–∂–∞–Ω–∏—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ø—ã—Ç–∫–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ü–æ–ª–∏—Ç–∑–∞–∫–ª—é—á–µ–Ω–Ω—ã–µ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ü–æ–ª–∏—Ç–∑–∞–∫–ª—é—á–µ–Ω–Ω—ã–π", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ü–ª–æ—â–∞–¥—å –ø–µ—Ä–µ–º–µ–Ω", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ë–æ–Ω–¥–∞—Ä–µ–Ω–∫–æ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–±—á–±", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ü–æ–≥–æ–Ω—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ü–∞–≥–æ–Ω—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("nexta", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–Ω–µ—Ö—Ç–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–£—Ö–æ–¥–∏!", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–°–∞—à–∞ 3%", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("3%", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("97%", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—É—Å–∞—Ç—ã–π", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("pasaran", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–¶–µ–ø–∫–∞–ª–æ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ö–æ–ª–µ—Å–Ω–∏–∫–æ–≤–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ö–∞–ª–µ—Å–Ω–∏–∫–æ–≤–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–õ–∞—Ç—É—à–∫–æ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–°—Ç—Ä–∞–Ω–∞ –¥–ª—è –∂–∏–∑–Ω–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ß–µ—Å—Ç–Ω—ã–µ –ª—é–¥–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ú–æ–ª–æ–¥–æ–π —Ñ—Ä–æ–Ω—Ç", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ï–≤—Ä–æ–ø–µ–π—Å–∫–∞—è –ë–µ–ª–∞—Ä—É—Å—å", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–≤–µ—Ä—ã–º", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–º–æ–∂–∞–º", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ø–µ—Ä–∞–º–æ–∂–∞–º", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ø–µ—Ä–∞–º–æ–≥–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ö–ì–ö", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ë–ß–ë", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("ü§ç‚ù§Ô∏èü§ç", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–≥—É–±–æ–ø", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–∫–≥–±", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–≥—ç–±–Ω—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–õ—É–≥–∞–±–µ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ª—É–∫–∞—à", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—Å—Ç—ã—á–∫–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ø–ª–æ—à—á—É", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–±–µ—Ä–∫—É—Ç", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("Imaguru", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–∏–º–∞–≥—É—Ä—É", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–†–∞–¥—ã—ë –°–≤–∞–±–æ–¥–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—É–≥–æ–ª–æ–≤–∫–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–∫–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—Ç—é—Ä—å–º–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–æ–∫—Ä–µ—Å—Ç–∏–Ω–∞", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–∂–æ–¥–∏–Ω–æ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ø–æ–≤–µ—Å—Ç–∫–∞", MaterialType.TG_KEYWORD))
    # mentions.append(UnwantedMaterial("—Å—É–¥", MaterialType.MENTION))
    mentions.append(UnwantedMaterial("–≤—ã–±–æ—Ä—ã", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–º–∞—Ä—à", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ö–∞—Ä–∞—Ç–µ–ª–∏ –ë–µ–ª–∞—Ä—É—Å–∏", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ë–µ–ª—Å–∞—Ç", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("BELSAT", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("—Ö–∞—Ä—Ç–∏—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–•–∞—Ä—Ç—ã—è", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–ª–æ—Å–∏–∫", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–í–Ø–°–ù–ê", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–º–æ—Ç–æ–ª—å–∫–æ", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–¥–∏–∫—Ç–∞—Ç–æ—Ä", MaterialType.TG_KEYWORD))
    mentions.append(UnwantedMaterial("–¥–∏–∫—Ç–∞—Ç—É—Ä–∞", MaterialType.TG_KEYWORD))

    # mentions.append(UnwantedMaterial("–ª—É–∫–∞—à–µ–Ω–∫–æ", MaterialType.MENTION))
    # mentions.append(UnwantedMaterial("–ø—É—Ç–∏–Ω", MaterialType.MENTION))

    # Write the results to the output file in JSON format
    with open(output_file, 'w') as file:
        json.dump([chat.to_dict() for chat in mentions], file, ensure_ascii=False, indent=2)

    # Print the number of mentions found
    print(f"Number of mentions found: {len(mentions)}")


def has_tg_mention(line):
    line_lower = line.lower()
    return ("@" in line_lower or
            "telegram" in line_lower or
            "—Ç–µ–ª–µ–≥—Ä–∞–º" in line_lower or
            re.search(r't\.me/([a-zA-Z0-9._]+)', line_lower) or
            re.search(r'ID.*?(\d+)', line_lower))
    # re.search(r'@(\w+)', line)


common_mentions = ["telegram", "facebook", "instagram", "–≤–∫–æ–Ω—Ç–∞–∫—Ç–µ", "vk", "twitter", "youtube", "joinchat",
                   "–æ–¥–Ω–æ–∫–ª–∞—Å—Å–Ω–∏–∫–∏", "tiktok", 'tik-tok', 'Tik-–¢–æ–∫', "addstikers", "addstickers",
                   "belarus"]


def extract_urls(line: string):
    if not "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–∞–π—Ç" in line.lower():
        return []
    url_pattern = re.compile(
        r'(((http|https)://)?[a-zA-Z0-9./?:@\-_=#]+\.([a-zA-Z]){2,6}([a-zA-Z0-9.&/?:@\-_=#])*)')
    found_urls = list(filter(filter_mentions(common_mentions), map(lambda x: x[0], url_pattern.findall(line))))
    found_urls = list(map(clear_url, found_urls))
    return list(map(lambda x: UnwantedMaterial(
        material=x,
        source=MaterialType.URL
    ), found_urls))


def clear_url(line):
    line = re.sub(r'((http|https)://)?', '', line)
    return re.sub(r'www.', '', line)


def filter_mentions(mentions):
    def filter_mention(line):
        for m in mentions:
            if m in line:
                return False
        return True

    return filter_mention


def extract_tg_names(line):
    if not has_tg_mention(line):
        return []
    chat_name_pattern = re.compile(r'"(.*?)"')
    return map(lambda x: UnwantedMaterial(
        material=x,
        source=MaterialType.TG_NAME
    ), list(chat_name_pattern.findall(line)))


def extract_tg_usernames(line):
    if not has_tg_mention(line):
        return []
    username_pattern = re.compile(r't\.me/([a-zA-Z0-9._]+)')
    username_pattern2 = re.findall(r'@([a-zA-Z0-9._]+)', line)
    return list(map(lambda x: UnwantedMaterial(
        material=x,
        source=MaterialType.TG_USERNAME
    ), list(filter(lambda x: len(x) > 2, username_pattern.findall(line) + username_pattern2))))


def extract_tg_ids(line):
    if not has_tg_mention(line):
        return []
    id_pattern = re.compile(r'ID.*?(\d+)')
    return list(map(lambda x: UnwantedMaterial(
        material=x,
        source=MaterialType.TG_ID
    ), list(id_pattern.findall(line))))


def has_instagram_mention(line):
    return "instagram" in line.lower() or "–∏–Ω—Å—Ç–∞–≥—Ä–∞–º" in line.lower() or re.search(r'instagram.com/([a-zA-Z0-9._]+)',
                                                                                   line)


def extract_instagram_names(line):
    if not has_instagram_mention(line):
        return []
    chat_name_pattern = re.compile(r'"(.*?)"')
    return list(map(lambda x: UnwantedMaterial(
        material=x,
        source=MaterialType.INSTAGRAM_NAME
    ), list(chat_name_pattern.findall(line))))


def extract_instagram_urls(line):
    if not has_instagram_mention(line):
        return []
    username_pattern = re.compile(r'instagram.com/([a-zA-Z0-9._]+)')
    username_pattern2 = re.findall(r'@([a-zA-Z0-9._]+)', line)
    return list(map(lambda x: UnwantedMaterial(
        material=x,
        source=MaterialType.INSTAGRAM_LINK
    ), list(username_pattern.findall(line)) + username_pattern2))


def process_line(line):
    found = []
    found.extend(extract_tg_names(line))
    found.extend(extract_tg_usernames(line))
    found.extend(extract_tg_ids(line))

    found.extend(extract_instagram_names(line))
    found.extend(extract_instagram_urls(line))
    found.extend(extract_urls(line))

    found = filter(
        lambda x: len(x.material) > 3 and
                  x.material.lower() not in ["", "telegram", "facebook", "instagram", "–≤–∫–æ–Ω—Ç–∞–∫—Ç–µ",
                                             "vk", "twitter",
                                             "youtube", "joinchat", "–æ–¥–Ω–æ–∫–ª–∞—Å—Å–Ω–∏–∫–∏", "tiktok",
                                             'tik-tok', 'Tik-–¢–æ–∫', "addstikers", "addstickers",
                                             "lida", "user", "belarus", "youtube.com", "anya", "–Ω–æ–≤—ã", "—Å—É–¥",
                                             "alexander", "most", "explore", "gmail.com", "tik tok", "ivan",
                                             "–Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è"],
        found)

    return found


if __name__ == "__main__":
    # Run the extraction
    # test_line = "–ê–∫–∫–∞—É–Ω—Ç \"belarusla\" —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —Å–µ—Ç–∏ \"Instagram\", –∏–º–µ—é—â–∏–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä https://www.instagram.com/belarusla?igshid=NDk5N2NIZjQ=."
    # print(has_instagram_mention(test_line))

    extract_telegram_mentions('ex.docx', 'cache/unwanted_2.json')
    # print(list(map(lambda x: x.to_str(), extract_instagram_urls(
    #     )
    # )))
    save_doc_to_plain("ex.docx", 'cache/unwanted.txt')

# hardwomenbelarus
